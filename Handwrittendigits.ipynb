{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0O8B3PlhEEo0"
   },
   "outputs": [],
   "source": [
    "#Author: Dasari sravan kumar\n",
    "from mlxtend.data import loadlocal_mnist  #mlxtend library for loading the dataset\n",
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvKThIcXEJcj"
   },
   "outputs": [],
   "source": [
    "#Function for loading the dataset\n",
    "def load_data():\n",
    "    X_train,Y_train=loadlocal_mnist(images_path=\"/home/sravan/Downloads/train-images-idx3-ubyte\"\n",
    "                      ,labels_path=\"/home/sravan/Downloads/train-labels-idx1-ubyte\")\n",
    "    \n",
    "    X_test,Y_test=loadlocal_mnist(images_path=\"/home/sravan/Downloads/t10k-images-idx3-ubyte\"\n",
    "                  ,labels_path=\"/home/sravan/Downloads/t10k-labels-idx1-ubyte\")\n",
    "    #preprocess the data\n",
    "    X_test=X_test/255\n",
    "    X_train=X_train/255\n",
    "    y_train=np.zeros((len(Y_train),10))\n",
    "    y_test=np.zeros((len(Y_train),10))\n",
    "\n",
    "    \n",
    "    #convert Y_train into binary array such that 1 in index i indicates the digit i\n",
    "    j=0\n",
    "    i=0\n",
    "    for y in Y_train:    \n",
    "        y_train[j][y]=1\n",
    "        j=j+1\n",
    "    for y in Y_test:    \n",
    "        y_test[i][y]=1\n",
    "        i=i+1\n",
    "    return(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OvK6AFCO9AX"
   },
   "outputs": [],
   "source": [
    "class neural_network:\n",
    "    def __init__(self,net):\n",
    "        self.net=net\n",
    "        self.weights=[] \n",
    "        self.biases=[]\n",
    "        self.z=[] \n",
    "        self.mininbatch_x=[]\n",
    "        self.mininbatch_y=[]\n",
    "        self.activations=[]\n",
    "        #Randoomly intialize the weights and biases of the network\n",
    "        for i in range(2):\n",
    "            self.weights.append(np.random.randn(net[i+1],net[i]))\n",
    "            self.biases.append(np.random.randn(net[i+1],1))\n",
    "    #Feed the input to the network\n",
    "    def feedforward(self,x):\n",
    "        self.z=[]\n",
    "        self.activations=[]\n",
    "        a=x\n",
    "        a=a.reshape((784,1))\n",
    "        for i in range(2):\n",
    "            w=self.weights[i]\n",
    "            b=self.biases[i]\n",
    "            o=np.dot(w,a)+b\n",
    "            self.z.append(o)\n",
    "            a=self.sigmoid(o)\n",
    "            self.activations.append(a)\n",
    "    #Backpropagate the error in the neural network and \n",
    "    def backpropagation(self,minibatchx,minibatchy,eeta,m):\n",
    "        h=[]\n",
    "        j=[]\n",
    "        h1=[]\n",
    "        j1=[]\n",
    "        for (x,y) in zip(minibatchx,minibatchy):\n",
    "            k=y\n",
    "            k=k.reshape((10,1))\n",
    "            network.feedforward(x)\n",
    "            delta=((network.activations[1])-k)*network.sigmoid_prime(network.z[1])\n",
    "            h.append((np.matmul(delta,np.transpose(network.activations[0]))))\n",
    "            j.append(delta)\n",
    "            g=x.reshape((784,1))\n",
    "            delta1=(np.matmul(np.transpose(network.weights[1]),delta))*(network.sigmoid_prime(network.z[0]))\n",
    "            h1.append((np.matmul(delta1,np.transpose(g))))\n",
    "            j1.append(delta1)\n",
    "            for i in range(10):\n",
    "                if(y[i]==1):\n",
    "                    k=i\n",
    "            #print(np.argmax(network.activations[1]),k)\n",
    "          \n",
    "        #Gradient descent to update weights and biases\n",
    "        network.weights[1]=network.weights[1]-((eeta/m)*(sum(h)))\n",
    "        network.weights[0]=network.weights[0]-((eeta/m)*(sum(h1)))\n",
    "        network.biases[1]=network.biases[1]-((eeta/m)*(sum(j)))\n",
    "        network.biases[0]=network.biases[0]-((eeta/m)*(sum(j1)))\n",
    "        \n",
    "    #Creates  minibatches of size 10\n",
    "    def create_mininbatch(self,x,y):\n",
    "        self.mininbatch_x=[]\n",
    "        self.mininbatch_y=[]\n",
    "        combined=list(zip(x,y))\n",
    "        random.shuffle(combined)\n",
    "        x[:],y[:]=zip(*combined)\n",
    "        for i in range(5990):\n",
    "            self.mininbatch_x.append(x[i:i+10])\n",
    "            self.mininbatch_y.append(y[i:i+10])\n",
    "    #It update the weights and biases of the network\n",
    "    def update(self,X_train,y_train,eta,m,iter_):\n",
    "        for i in range(iter_):\n",
    "            self.create_mininbatch(X_train,y_train)\n",
    "            for (x,y) in zip(self.mininbatch_x,self.mininbatch_y):\n",
    "                self.backpropagation(x,y,eta,m)\n",
    "            print('Iteration #%d -- Total score = %d.' %(i, self.evaluate(X_train,y_train)))  \n",
    "            print('Test score = %d.' %(network.evaluate(X_test,y_test)))\n",
    "    #It evaluates the model and gives us the score\n",
    "    def evaluate(self,X,Y):\n",
    "        score=0\n",
    "        for (x,y) in zip(X,Y):\n",
    "            self.feedforward(x)\n",
    "            for i in range(len(y)):\n",
    "                if(y[i]==1):\n",
    "                    label=i     \n",
    "            if(np.argmax(network.activations[1])==label):\n",
    "                score=score+1\n",
    "        return(score)\n",
    "        \n",
    "    #Activation function\n",
    "    def sigmoid(self,x):\n",
    "        return(1/(1+(np.exp(-x))))\n",
    "    #derivative of activation function\n",
    "    def sigmoid_prime(self,x):\n",
    "        return(self.sigmoid(x)*(1-self.sigmoid(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "X_train,y_train,X_test,y_test=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1163
    },
    "colab_type": "code",
    "id": "DF5XwLflPVJA",
    "outputId": "8bb103b0-7931-4d6a-91f8-335fc1dbb706"
   },
   "outputs": [],
   "source": [
    "net=[784,30,10] #Indicates 784 nodes in the input layer,30 nodes in the hidden layer and 10 nodes in the output layer\n",
    "network=neural_network(net) #create a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeta=3 #Learning rate\n",
    "m=10   #size of minibatch\n",
    "iter_=30 #No.of iterations\n",
    "network.update(X_train,y_train,eeta,m,iter_)\n",
    "#evaluate for the test data:\n",
    "network.evaluate(X_test,y_test)\n",
    "print('Test score = %d.' %(network.evaluate(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
